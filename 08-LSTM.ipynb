{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18081c3b",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)\n",
    "\n",
    "LSTM or Long Short-Term Memory network is one of the popular deep learning models. The LSTM models are popularly applied to sequential data due to their capability to process the sequences. They are largely applied to natural language processing and time series forecasting applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbc7d9",
   "metadata": {},
   "source": [
    "### What is the Long Short-Term Memory (LSTM) Network?\n",
    "\n",
    "LSTM or Long-Short-Term Memory networks are a type of Recurrent Neural Network (RNN). These are the advanced variants of Artificial Neural Networks. Unlike the feedforward networks where the signals travel in the forward direction only, in LSTM RNN, the data signals travel in backward directions as well as these networks have feedback connections. They are widely used today for a variety of different tasks like speech recognition, text classification, sentimental analysis, time series forecasting etc. \n",
    "\n",
    "A recurrent neural network is a type of ANN that is used when users want to perform predictive operations on sequential or time-series based data. These Deep learning layers are commonly used for ordinal or temporal problems such as Natural Language Processing, Neural Machine Translation, automated image captioning tasks and likewise.\n",
    "\n",
    "The main difference between the RNN and CNN is that RNN is incorporated with memory to take any information from prior inputs to influence the Current input and output. Training methods for this network are the same. While traditional neural networks assume that both input and output are independent of each other, RNN gives the output based on previous input and its context.  \n",
    "\n",
    "Another distinguishing parameter is that RNN shares parameters across each layer of the network. While feedforward networks have different weights across each node, recurrent neural networks share the same weight parameter within each layer of the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
