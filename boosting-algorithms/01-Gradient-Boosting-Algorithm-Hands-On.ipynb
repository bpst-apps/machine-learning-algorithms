{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53577dc",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classification in Python\n",
    "\n",
    "Here, we will apply the gradient boosting technique to a real-world classification problem where our task is to predict whether a given patient is diabetic or not from a certain set of medical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c6dad",
   "metadata": {},
   "source": [
    "####  Load and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c2b125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required library\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Checking top 5 rows of dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196870e0",
   "metadata": {},
   "source": [
    "Now let’s quickly check the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2248b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b522784",
   "metadata": {},
   "source": [
    "As we can see from the above two outputs, out of 9 columns the first 8 columns will be treated as input features, and the last Outcome column holds the diabetes status of the patients in binary form which is our output feature. \n",
    "\n",
    "The output feature holds the two class labels that are 0 (non-diabetic) and 1 (diabetic), now we will check the distribution of these class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8330af44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class label count\n",
    "data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6a8835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage distribution\n",
    "data['Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953084d9",
   "metadata": {},
   "source": [
    "Out of the records of all 768 patients, there are 500 or 65.10% patients who do not have diabetes and 268 or 34.89% patients who have diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2709a0",
   "metadata": {},
   "source": [
    "#### Defining input-output features\n",
    "\n",
    "As of now, we have got a basic understanding of our dataset. In the previous step, we identified a set of input features and one output feature; below we define those as X and y respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fd5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input (X) and output (y) features\n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e37661",
   "metadata": {},
   "source": [
    "After defining X and y, now we will create a separate training and testing dataset by using SK-Learn’s `train_test_split()` method, and later this dataset will be used in the training and testing phase respectively.  Out of 768 records we are keeping 10% records for testing the model and the rest 90% will be used for training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7353201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test patterns\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, shuffle=True, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ff93b",
   "metadata": {},
   "source": [
    "Now let’s check the shape of the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d2ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((691, 8), (77, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of training and test sets\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c4182",
   "metadata": {},
   "source": [
    "From the above shapes, 77 records or 10% of the total records will be used to evaluate the performance of the model, and the model will be trained by the rest of 691 records.  \n",
    "\n",
    "Before moving to the model building let's take a look at input features patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8cd99ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.00e+00, 1.54e+02, 7.40e+01, ..., 2.93e+01, 8.39e-01, 3.90e+01],\n",
       "       [4.00e+00, 8.30e+01, 8.60e+01, ..., 2.93e+01, 3.17e-01, 3.40e+01],\n",
       "       [1.00e+00, 9.70e+01, 7.00e+01, ..., 3.81e+01, 2.18e-01, 3.00e+01],\n",
       "       ...,\n",
       "       [4.00e+00, 9.40e+01, 6.50e+01, ..., 2.47e+01, 1.48e-01, 2.10e+01],\n",
       "       [1.10e+01, 8.50e+01, 7.40e+01, ..., 3.01e+01, 3.00e-01, 3.50e+01],\n",
       "       [5.00e+00, 1.36e+02, 8.20e+01, ..., 0.00e+00, 6.40e-01, 6.90e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input patterns\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589c8a9",
   "metadata": {},
   "source": [
    "#### Initializing and training and Gradient Boosting Classifier\n",
    "\n",
    "In this step first, we will import the Gradient boosting classifier from the sklearn library and will initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321373ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60efae",
   "metadata": {},
   "source": [
    "The GBM classifier deals with a certain set of hyperparameters which can help us to maximize the performance of the classifier. Out of those all hyperparameters, the `learning rate`, and `loss function` play a crucial role so we are going to tune these two parameters with GridSearchCV, and the rest parameters will be kept at their default values. \n",
    "\n",
    "The GridSearchCV searches for the optimal value of hyperparameters from a range of values given by the user and returns the best possible settings. In our case, grid search will give the best learning rate from  0.01,0.1,1 and the best loss function from log loss, and exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c176d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'loss': 'exponential'}\n"
     ]
    }
   ],
   "source": [
    "# Get values for lr, loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# prams to be searched\n",
    "param_grid  = {'learning_rate': [0.01,0.1,1], 'loss': ['log_loss','exponential']}\n",
    "grid = GridSearchCV(classifier, param_grid, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a856b7",
   "metadata": {},
   "source": [
    "As we see from the above output Grid search has returned the optimal value for learning rate and loss as 0.1 and exponential respectively. Now let’s train the classifier with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0dbba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(loss=&#x27;exponential&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(loss=&#x27;exponential&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the GBM classifier\n",
    "classifier = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c37bae",
   "metadata": {},
   "source": [
    "#### Predicting and evaluating the classifier\n",
    "\n",
    "After successfully training the classifier, now let’s obtain the prediction on the test dataset. And compare it with actual values side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1430af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Outcomes</th>\n",
       "      <th>Predicted Outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Outcomes  Predicted Outcomes\n",
       "0                1                   1\n",
       "1                0                   0\n",
       "2                0                   0\n",
       "3                1                   1\n",
       "4                0                   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions with the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Combining the actual and predicted values\n",
    "pd.DataFrame(data={'Actual Outcomes': y_test, 'Predicted Outcomes': y_pred}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d679a9",
   "metadata": {},
   "source": [
    "All above 5 predicted labels are matched perfectly with actual labels but there might be some labels that are incorrectly predicted so let’s look at all predictions using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f6c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thaku\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW+UlEQVR4nO3de9RVdZ3H8feHm4CKihCiYJKiRpToEN7SEG9YrcBZmpemZUmRY9p9GmWcbGxay1YXcybNQTTRTPOSt1LRCAetvKAiCkyJKYmgXBQFRYTn+c4fez9yIJ7n7A3nsvfD57XWXp69zz6//QWXX3+/3/5dFBGYmZVZl2YHYGa2tZzIzKz0nMjMrPScyMys9JzIzKz0ujU7gEr9+naNvQZ3b3YYlsNf5vRudgiWw9u8yTuxVltTxvFHbR8rXm3JdO/jc9ZOi4ixW/O8LAqVyPYa3J1Hpw1udhiWw/G7j2h2CJbDIzF9q8tY/moLj0wblOne7gOf67fVD8ygUInMzMogaInWZgexEScyM8slgFaKNZDeiczMcmvFNTIzK7EgWOempZmVWQAtblqaWdm5j8zMSi2AloKtmuNEZma5FauHzInMzHIKwn1kZlZuEbCuWHnMiczM8hItbNV0zZpzIjOzXAJodY3MzMrONTIzK7VkQKwTmZmVWADrolhrsjqRmVkugWgp2OLSTmRmlltruGlpZiXmPjIz6wRES8H6yIoVjZkVXrJCbJdMRxaSukp6UtJv0vMhkh6RtEDSryT1qFaGE5mZ5RIh3omumY6MvgLMrzj/PnBJROwDvAZMqFaAE5mZ5daKMh3VSBoEfByYkp4LGAPckt4yFRhfrRz3kZlZLklnf+Y6UD9JsyrOJ0fE5IrznwDfAnZMz3cFVkbE+vR8EbBHtYc4kZlZTrk6+5dHxMjNliJ9AlgaEY9LGr01ETmRmVkubZ39NXA48ElJHwN6An2AS4GdJXVLa2WDgJeqFeQ+MjPLrSWU6ehIRJwfEYMiYi/gVOD3EfFpYAZwUnrbGcAd1eJxIjOzXAKxLrplOrbQvwJfl7SApM/sqmo/cNPSzHLJ2dmfrcyIB4AH0s9/BUbl+b0TmZnlElRvNjaaE5mZ5Vajzv6acSIzs1wiKNxcSycyM8sl6ezPPP2oIZzIzCw3L6xoZqUWyAsrmln5uUZmZqWW7GvpRGZmpeadxs2s5JLt4PzW0sxKLEJuWppZ+XlArJmVWrIemfvIzKzUircdnBOZmeWSDL9wjczMSsxzLc2sU/AyPmZWaskyPm5amlnJuY/MzEotWf3CTUszK7FkitLWJzJJPYGZwHYkueiWiLhQ0jXAR4HX01s/GxGzOyrLiawOWlrg3LH7suvAdXz32uffvX75BXsw7ca+3LHg6SZGZ+0ZtPfbTLpi4bvnu+35Dtf9YDdum9K/iVEVUc1qZGuBMRGxWlJ34CFJ96Tf/UtE3JK1oLomMkljSXYO7gpMiYiL6/m8orh9Sn8GD13LW6s3/Mv+y1O9WP16sV5Z28YWPdeTs4/dD4AuXYLrn5jHH+7ZqclRFVMtRvZHRACr09Pu6RFbUlbdGrqSugKXAScAw4DTJA2r1/OKYtni7jw6vQ8nnL7i3WstLXDld3dnwgWLmxiZ5THiiNUsWdiDpS/1aHYohdP21jLjTuP9JM2qOCZWliWpq6TZwFLg/oh4JP3qe5LmSLpE0nbVYqpnjWwUsCDdbBNJNwLjgHl1fGbTXXHhHnz+gsW8tXpD7evOn/fj0OPeYNcB65sYmeUxetxrPHD7Ls0Oo7ByNC2XR8TI9r6MiBZghKSdgdskDQfOB14GegCTSXYev6ijh9Tz1cMewIsV54vSaxuRNLEtWy9b0VLHcOrv4fv7sHO/9Qz90Jp3r614uRsP3rUz485c1sTILI9u3Vs55Lg3mHmXm5Wb07Zmf5Yjc5kRK4EZwNiIWBKJtcDPybDreNM7+yNiMknWZeQBPbeofVwU8x7bnofv68Nj04fxzlrx1qquTDxqf7r3CD53WNKqXrumC5897P1c88f5TY7W2vPhMatY8HQvVi7v3uxQCimA9bV5a9kfWBcRKyX1Ao4Fvi9pYEQskSRgPPBMtbLqmcheAgZXnA9Kr3VaZ05awpmTlgDw1B934JYr+m/01hJg3D4fdBIruNHjV7pZWUWN3loOBKam/eldgJsi4jeSfp8mOQGzgbOqFVTPRPYYMFTSEJIEdipweh2fZ7bVtuvVwkFHrOLSbw1qdijFlbPZ2G4xEXOAAzdzfUzesuqWyCJivaRzgGkkwy+ujoi59Xpe0Rxw2GoOOGz13133GLJiW7umKycPH97sMAptm1tYMSLuBu6u5zPMrPE819LMSs0LK5pZ6QVifasnjZtZyW1TfWRm1gmFm5ZmVnLuIzOzTsGJzMxKLRAt7uw3s7JzZ7+ZlVq4s9/MOoNwIjOzcqvNpPFaciIzs9xcIzOzUouAllYnMjMrOb+1NLNSC9y0NLPSc2e/mXUCUbBtgpzIzCy3ojUtizVhyswKL3lr2SXT0RFJPSU9KukpSXMl/Ud6fYikRyQtkPQrSVW3e3ciM7PcIrIdVawFxkTEAcAIYKykQ4DvA5dExD7Aa8CEagU5kZlZbhHKdHRcRkREtG011j09AhgD3JJen0qySW+HnMjMLJcgWxLL0o8mqauk2cBS4H7gOWBlRKxPb1kE7FGtHHf2m1luOV5a9pM0q+J8ckRMfreciBZghKSdgduA/bckHicyM8snILJPUVoeESOrFhmxUtIM4FBgZ0nd0lrZIOClar9309LMcqtF01JS/7QmhqRewLHAfGAGcFJ62xnAHdXicY3MzHKr0YDYgcBUSV1JKlU3RcRvJM0DbpT0n8CTwFXVCmo3kUn6bzpoCkfEl3OHbWalV6u5lhExBzhwM9f/CozKU1ZHNbJZHXxnZtuqAAo2sr/dRBYRUyvPJfWOiLfqH5KZFV3R5lpW7eyXdGjaZv2/9PwASZfXPTIzKygRrdmORsny1vInwPHACoCIeAo4so4xmVnRRcajQTK9tYyIF6WNsmtLfcIxs8KL4q1+kSWRvSjpMCAkdQe+QjLWw8y2VWXrIwPOAr5EMt9pMcks9S/VMSYzKzxlPBqjao0sIpYDn25ALGZWFq3NDmBjWd5avk/SXZKWSVoq6Q5J72tEcGZWQG3jyLIcDZKlaflL4CaS6QS7AzcDN9QzKDMrthotrFgzWRJZ74i4LiLWp8cvgJ71DszMCqwswy8k9U0/3iPpPOBGktBOAe5uQGxmVlQlGn7xOEniaov4ixXfBXB+vYIys2JTwYZfdDTXckgjAzGzkghBA6cfZZFpZL+k4cAwKvrGIuLaegVlZgVXlhpZG0kXAqNJEtndwAnAQ4ATmdm2qmCJLMtby5OAo4GXI+JzwAHATnWNysyKrSxvLSusiYhWSesl9SHZtmlwneMys6Iq08KKFWalGwRcSfImczXwp3oGZWbFVpq3lm0i4uz04xWS7gX6pGttm9m2qiyJTNJBHX0XEU/UJyQzK7oy1ch+1MF3AYypcSz8ZU5vjt99RK2LtTpa8flDmx2C5bD+todrU1AN+sgkDSYZ/TCAJKdMjohLJX0H+AKwLL11UkR0OJuoowGxR211pGbW+dTujeR64BsR8YSkHYHHJd2ffndJRPwwa0HeoNfM8qtBIouIJcCS9PMqSfNJFnDNLcs4MjOzjag12wH0kzSr4pi42fKkvUg2630kvXSOpDmSrpa0S7V4nMjMLL/sA2KXR8TIimPypkVJ2gG4FfhqRLwB/AzYm2RZ/SV03F8PZFshVpL+SdK30/M9JeXaztzMOg9F9qNqWcmGRrcC10fErwEi4pWIaImIVpLxq1XzTZYa2eXAocBp6fkq4LIMvzOzzqoGS10r2WPyKmB+RPy44vrAittOBJ6pFk6Wzv6DI+IgSU8CRMRrknpk+J2ZdVa1eWt5OPAZ4GlJs9Nrk4DTJI1In/ICG6+FuFlZEtk6SV3TQpHUn8LtoWJmjVSLAbER8RCb3zMu9wrUWRLZfwG3Ae+R9D2S1TAuyPsgM+sk4t03koWRZa7l9ZIeJ1nKR8D4iPBO42bbshJNUQKSt5TAW8Bdldci4m/1DMzMCqxsiQz4LRs2IekJDAH+DHygjnGZWYGVadI4ABHxwcrzdFWMs9u53cys4XLPtUwneB5cj2DMrCTKViOT9PWK0y7AQcDiukVkZsVWxreWwI4Vn9eT9JndWp9wzKwUylQjSwfC7hgR32xQPGZWcKJEnf2SukXEekmHNzIgMyuBsiQy4FGS/rDZku4EbgbebPuybaa6mW1jMq5s0UhZ+sh6AitI1uhvG08WgBOZ2baqRJ3970nfWD7DhgTWpmD52MwaqUw1sq7ADmx+dnrB/hhm1lAFywAdJbIlEXFRwyIxs3Ko3S5KNdNRItv6jevMrFMqU9Py6IZFYWblUpZEFhGvNjIQMyuPMk5RMjPboGR9ZGZmf0cUrwPdG/SaWX7ZN+htl6TBkmZImidprqSvpNf7Srpf0rPpP73TuJnVXo026F0PfCMihgGHAF+SNAw4D5geEUOB6el5h5zIzCy/GtTIImJJRDyRfl4FzAf2AMYBU9PbpgLjq4XjPjIzyyffwor9JM2qOJ8cEZM3vUnSXsCBwCPAgIhYkn71MjCg2kOcyMwsv+xvLZdHxMiObpC0A8lirV+NiDekDa8SIiKk6o1UNy3NLLca9ZEhqTtJEru+YmmwVyQNTL8fCCytVo4TmZnlV5u3lgKuAuZHxI8rvroTOCP9fAZwR7Vw3LQ0s9xqNNfycOAzwNOSZqfXJgEXAzdJmgAsBD5VrSAnMjPLJ6jJwooR8RDtj63NNdfbiczMcinV5iNmZu1yIjOzslMUK5M5kZlZPl79wsw6A/eRmVnpeWFFMys/18jMrNRKutO4mdnGnMjMrMw8INbMOgW1FiuTOZGZWT4eR7ZtGbT320y6YuG757vt+Q7X/WA3bpvSv4lRWaVvj5/BR/ZdyGtv9uKUy04BYOiA5Zz/yQfp3WMdi1fuyL/fcjRvru3R5EiLpWjDL+q2HpmkqyUtlfRMvZ5RdIue68nZx+7H2cfuxznH78vaNV34wz07NTssq3DXk/tx7nUf3+jaBeP/l5/efzCnXvYpHpg3hM8cPrs5wRVZDdYjq6V6Lqx4DTC2juWXyogjVrNkYQ+WvuT/sxfJkwt3540122107b27vs4TLwwE4JHnBjFm2PPNCK3QarVCbK3ULZFFxEzg1XqVXzajx73GA7dX3Z7PCuC5pbvw0f1fAOCY4c8xYKfVzQ2oaAKIyHY0SNOXupY0UdIsSbPWsbbZ4dRFt+6tHHLcG8y8y83KMrjo9tGcPGou1511C717rGNdS9P/MykctWY7GqXpnf3p1lCTAfqob8HehdTGh8esYsHTvVi5vHuzQ7EMFi7fhXOu/QQAe+66ko/su7DKL7YtRRxH5v/VNMDo8SvdrCyRXbZfA4AUTPjoE9z62AeaHFHBZG1WNrBp2fQaWWe3Xa8WDjpiFZd+a1CzQ7HN+N5Jv+Mfhixm595v89tvXMfkGSPp1WMdJ4+aC8CM+UO488n9mhxl8RStRla3RCbpBmA0yU7Di4ALI+Kqej2vqNau6crJw4c3Owxrx7/dcsxmr9/48IcaHEnJbCuJLCJOq1fZZtZctaqRSboa+ASwNCKGp9e+A3wBWJbeNiki7u6oHPeRmVk+AbREtqO6a9j8eNNLImJEenSYxMB9ZGa2BWpVI4uImZL22tpyXCMzs/yyv7Xs1zZOND0mZnzCOZLmpFMdq77ydyIzs9xyTFFaHhEjK47JGYr/GbA3MAJYAvyo2g+cyMwsn6wTxrew+RkRr0RES0S0AlcCo6r9xn1kZpaLAGXryN+y8qWBEbEkPT0RqLqCjhOZmeVWq53GNzfeFBgtaQRJne4F4IvVynEiM7N8arjWWDvjTXMPnHciM7OcGjuPMgsnMjPLbZuZa2lmnZhrZGZWalHft5ZbwonMzPIrVh5zIjOz/Go1/KJWnMjMLD8nMjMrtQAKtkGvE5mZ5SLCTUsz6wRai1UlcyIzs3zctDSzzsBNSzMrPycyMys3Txo3s7Jr20WpQJzIzCw395GZWfk5kZlZqQXQ6kRmZqXmzn4z6wwKlsi8r6WZ5RNAS2u2o4p0J/Glkp6puNZX0v2Snk3/6Z3GzazWAqI121HdNcDYTa6dB0yPiKHA9PS8Q05kZpZfRLajajExE3h1k8vjgKnp56nA+GrluI/MzPLJ99ayn6RZFeeTI2Jyld8MqNhp/GVgQLWHOJGZWX7ZO/uXR8TILX9MhFR98zk3Lc0svxo1LdvxiqSBAOk/l1b7gROZmeUTAS0t2Y4tcydwRvr5DOCOaj9wIjOz/GpUI5N0A/AnYD9JiyRNAC4GjpX0LHBMet4h95GZWX41GhAbEae189XRecpxIjOznMJzLc2s5AIi22DXhnEiM7P8Mkw/aiQnMjPLJ8LbwZlZJ1Cw1S+cyMwst3CNzMzKzQsrmlnZealrMyu7AGLLpx/VhROZmeUTkXXRxIZxIjOz3MJNSzMrvYLVyBQFevsgaRmwsNlx1EE/YHmzg7BcOuu/s/dGRP+tKUDSvSR/P1ksj4hN1+SvuUIlss5K0qytWSXTGs//zsrF65GZWek5kZlZ6TmRNUa1XWOsePzvrETcR2ZmpecamZmVnhOZmZWeE1kdSRor6c+SFkg6r9nxWHWSrpa0VNIzzY7FsnMiqxNJXYHLgBOAYcBpkoY1NyrL4Bqg7gM4rbacyOpnFLAgIv4aEe8ANwLjmhyTVRERM4FXmx2H5eNEVj97AC9WnC9Kr5lZjTmRmVnpOZHVz0vA4IrzQek1M6sxJ7L6eQwYKmmIpB7AqcCdTY7JrFNyIquTiFgPnANMA+YDN0XE3OZGZdVIugH4E7CfpEWSJjQ7JqvOU5TMrPRcIzOz0nMiM7PScyIzs9JzIjOz0nMiM7PScyIrEUktkmZLekbSzZJ6b0VZ10g6Kf08paMJ7ZJGSzpsC57xgqS/222nveub3LM657O+I+mbeWO0zsGJrFzWRMSIiBgOvAOcVfmlpC3apzQiPh8R8zq4ZTSQO5GZNYoTWXk9COyT1pYelHQnME9SV0k/kPSYpDmSvgigxE/T9dF+B7ynrSBJD0gamX4eK+kJSU9Jmi5pL5KE+bW0NniEpP6Sbk2f8Zikw9Pf7irpPklzJU0BVO0PIel2SY+nv5m4yXeXpNenS+qfXttb0r3pbx6UtH9N/jat1LzTeAmlNa8TgHvTSwcBwyPi+TQZvB4RH5a0HfAHSfcBBwL7kayNNgCYB1y9Sbn9gSuBI9Oy+kbEq5KuAFZHxA/T+34JXBIRD0nak2T2wvuBC4GHIuIiSR8HsoyKPzN9Ri/gMUm3RsQKYHtgVkR8TdK307LPIdkU5KyIeFbSwcDlwJgt+Gu0TsSJrFx6SZqdfn4QuIqkyfdoRDyfXj8O+FBb/xewEzAUOBK4ISJagMWSfr+Z8g8BZraVFRHtrct1DDBMerfC1UfSDukz/jH97W8lvZbhz/RlSSemnwensa4AWoFfpdd/Afw6fcZhwM0Vz94uwzOsk3MiK5c1ETGi8kL6H/SblZeAcyNi2ib3fayGcXQBDomItzcTS2aSRpMkxUMj4i1JDwA927k90ueu3PTvwMx9ZJ3PNOCfJXUHkLSvpO2BmcApaR/aQOCozfz2YeBISUPS3/ZNr68Cdqy47z7g3LYTSSPSjzOB09NrJwC7VIl1J+C1NIntT1IjbNMFaKtVnk7SZH0DeF7SyekzJOmAKs+wbYATWeczhaT/64l0A43/Ial53wY8m353LckKDxuJiGXARJJm3FNsaNrdBZzY1tkPfBkYmb5MmMeGt6f/QZII55I0Mf9WJdZ7gW6S5gMXkyTSNm8Co9I/wxjgovT6p4EJaXxz8fLhhle/MLNOwDUyMys9JzIzKz0nMjMrPScyMys9JzIzKz0nMjMrPScyMyu9/wdr71ge+L6pRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(classifier, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951ec33",
   "metadata": {},
   "source": [
    "As we can see the confusion metrics that help us reveal the complete truth of the predictions. So there are 44+19=63 correctly identified labels and 7+7=14 incorrectly identified labels. The combined accuracy is 63 / (63+14) =  0.8181 which is nothing but the testing accuracy. This same accuracy can be obtained by the metric called accuracy_score as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70209537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e3edb",
   "metadata": {},
   "source": [
    "Now we do the final evaluation of this classifier by using the classification report which returns the score for various metrics between 0 and 1. A score closer to 1 resembles a good-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d996c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        51\n",
      "           1       0.73      0.73      0.73        26\n",
      "\n",
      "    accuracy                           0.82        77\n",
      "   macro avg       0.80      0.80      0.80        77\n",
      "weighted avg       0.82      0.82      0.82        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27598b01",
   "metadata": {},
   "source": [
    "In the above report, we have obtained a satisfactory score for all the metrics which inherently results that we have a good-performing classification model. \n",
    "\n",
    "As we have seen GBM performs well on classification problems, In a similar way, we can use the GBM for a regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba45098",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression in Python\n",
    "\n",
    "As we have gone through an application of GBM in a classification problem, in this part, we will implement this technique in a regression problem. \n",
    "\n",
    "To address the regression problem using GBM we are considering a dataset where our task is to predict the health insurance premium from a given set of attributes. The dataset contains a total of 7 features out of which 6 will be the predictors (input features) and one will be the target (output feature) column. \n",
    "\n",
    "So to implement regression problem using the Gradient Boosting Machine technique in Python, the following steps are to be followed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2e93e",
   "metadata": {},
   "source": [
    "#### Read and load the data\n",
    "\n",
    "As usual first we will load the data using pandas and will observe the top 5 rows of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86d5a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Visualize the top 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7f713",
   "metadata": {},
   "source": [
    "Now let’s quickly review the basic information of this dataset using the .info() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0f1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f41a43",
   "metadata": {},
   "source": [
    "We have a total of 1338 records and 7 columns to deal with. Out of these 7 columns, the first 6 starting from index position 0 to 5 will be our input features, and the last column named charges is the output feature that holds the continuous values to be learned and predicted by the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b95f7f",
   "metadata": {},
   "source": [
    "#### Preprocess and define input(x)-output(y) features\n",
    "\n",
    "As we can see, in our input features there are 3 textual categorical columns and we need to convert those into numbers. For this purpose, we are using the LabelEncoder class from the sklearn library that represents data into numbers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0013b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extract categorical columns\n",
    "cat_columns = data.select_dtypes('object').columns\n",
    "\n",
    "# Encode the columns\n",
    "data[cat_columns] = data[cat_columns].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06ebca",
   "metadata": {},
   "source": [
    "Now we have successfully converted the textual categorical data into a number. In the previous step, we identified a set of input features and one output feature; below we define those as X and y respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d530816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input (X) and output (y) features\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6669c6",
   "metadata": {},
   "source": [
    "To train and evaluate the model we must have two different sets of data that will be used in respective phases. Below we are going to create these two sets namely the training and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eb4df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test patterns\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, shuffle=True, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47204b",
   "metadata": {},
   "source": [
    "After splitting the data let's quickly check the shape of the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb410170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (268, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of training and test sets\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043c53b",
   "metadata": {},
   "source": [
    "Before moving further let’s quickly have a sanity check by observing the input patterns so that we can ensure that data is ready for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b964c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.  ,  1.  , 34.1 ,  4.  ,  1.  ,  3.  ],\n",
       "       [18.  ,  1.  , 34.43,  0.  ,  0.  ,  2.  ],\n",
       "       [23.  ,  0.  , 36.67,  2.  ,  1.  ,  0.  ],\n",
       "       ...,\n",
       "       [40.  ,  1.  , 25.08,  0.  ,  0.  ,  2.  ],\n",
       "       [19.  ,  1.  , 35.53,  0.  ,  0.  ,  1.  ],\n",
       "       [33.  ,  0.  , 18.5 ,  1.  ,  0.  ,  3.  ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input patterns\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a3e01",
   "metadata": {},
   "source": [
    "As we can see our data looks fine and we did all the necessary preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b56ae2",
   "metadata": {},
   "source": [
    "#### Initialize and train GBM regressor\n",
    "\n",
    "As we did in the classification problem here the GBM regressor can be imported from the sklearn library and we create an instance of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfbd3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Gaussian Naive Bayes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "regressor = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08242fb2",
   "metadata": {},
   "source": [
    "Now will train the regressor with all default values of Hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7517891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the SVM classifier\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73a532",
   "metadata": {},
   "source": [
    "#### Predicting and evaluating the GBM regressor\n",
    "\n",
    "After successfully training the regressor let’s obtain the prediction on test data and compare it side-by-side with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d4a9206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Charges</th>\n",
       "      <th>Predicted Charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9724.53000</td>\n",
       "      <td>12141.827923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8547.69130</td>\n",
       "      <td>9538.762935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45702.02235</td>\n",
       "      <td>45616.085830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12950.07120</td>\n",
       "      <td>13958.936934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9644.25250</td>\n",
       "      <td>10330.394823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Charges  Predicted Charges\n",
       "0      9724.53000       12141.827923\n",
       "1      8547.69130        9538.762935\n",
       "2     45702.02235       45616.085830\n",
       "3     12950.07120       13958.936934\n",
       "4      9644.25250       10330.394823"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on the test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Comparing the predicted profits with actual profits\n",
    "pd.DataFrame(data={ 'Actual Charges': y_test,'Predicted Charges': y_pred}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be7905",
   "metadata": {},
   "source": [
    "As we can see in the comparison few predictions are closer to the actual values and few have differences. To ensure the performance of the model, now we will evaluate this GBM regressor using Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-Squared, and Adjusted R-Squared metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8de70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error is: 16212736.429638132\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE=mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error is:', MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373b420",
   "metadata": {},
   "source": [
    "The MSE returns the average squared difference between actual and predicted values and the above looks too large. As it is the squared error, let's take root over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2445dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error is: 4026.5042443338034\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Squared Error (RMSE)\n",
    "import math\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('Root Mean Squared Error is:', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a928b3",
   "metadata": {},
   "source": [
    "RMSE tells us the standard deviation of the residuals (prediction errors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0476bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared is: 0.8981163811449989\n"
     ]
    }
   ],
   "source": [
    "# R-Squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-Squared is:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31974fd8",
   "metadata": {},
   "source": [
    "s we can see the R-squared value is close to 1 which indicates we have the best fit model. We are dealing with the multi-regression problem. It is better to conclude our evaluation using an adjusted R-squared value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89a8e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-Squared is: 0.8975413089783667\n"
     ]
    }
   ],
   "source": [
    "# Adjusted R-Squared\n",
    "adj = 1-(\n",
    "         (1-r2)*(X_train.shape[0]-1)/\n",
    "          (X_train.shape[0]-X_train.shape[1]-1)\n",
    "          )\n",
    "print('Adjusted R-Squared is:', adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f108889",
   "metadata": {},
   "source": [
    "As we can see, the scores of Adjusted R-Squared and R-Squared are very close to each other which tells us that having multiple independent features has not affected the performance of the model. \n",
    "\n",
    "So this is how we can implement the Gradient Boosting Machine for both classification and regression problems on real-world datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
