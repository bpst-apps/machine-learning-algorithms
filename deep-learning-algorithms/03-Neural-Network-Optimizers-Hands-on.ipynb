{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490f6bc7",
   "metadata": {},
   "source": [
    "## Implementing different neural net optimizers\n",
    "\n",
    "The optimizer name itself explains that it helps to optimize certain processes. Here in neural networks, the optimizers are incorporated with loss function with the goal of minimizing the value of loss function. More specifically, the optimizers help the cost function to coverage at global minima. \n",
    "\n",
    "In this notebook, we are going to check the behaviour of some popular optimizers of NN. Our task is to evaluate the performance of the standard ANN model on different optimizers. Here the task of the ANN model is to classify the genders based on the different physical aspects of the human face. For each optimizer, we will initialize the model, new losses and accuracy will be recorded. \n",
    "\n",
    "So following steps are to be taken to evaluate the optimizers of the neural networks.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b6849",
   "metadata": {},
   "source": [
    "#### Reading the dataset\n",
    "\n",
    "The dataset that we are using to train the model is stored in a CSV file, so first we will take the data into our system using the Pandas library and will brief the data by checking the first 5 rows of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d26421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "0          1               11.8                 6.1          1          0   \n",
       "1          0               14.0                 5.4          0          0   \n",
       "2          0               11.8                 6.3          1          1   \n",
       "3          0               14.4                 6.1          0          1   \n",
       "4          1               13.5                 5.9          0          0   \n",
       "\n",
       "   lips_thin  distance_nose_to_lip_long  gender  \n",
       "0          1                          1    Male  \n",
       "1          1                          0  Female  \n",
       "2          1                          1    Male  \n",
       "3          1                          1    Male  \n",
       "4          0                          0  Female  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('gender_classification.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72767659",
   "metadata": {},
   "source": [
    "Let’s check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274a3aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3137a",
   "metadata": {},
   "source": [
    "There are a total of 5001 rows and 8 columns are variable to train and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169b970",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "As we are dealing with a classification problem it is necessary to check the class distribution of the outcome variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d05a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    2501\n",
       "Male      2500\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting labels\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72867873",
   "metadata": {},
   "source": [
    "We can see that the classes are distributed very well and there is a need for class balancing. But you might have observed that the classes are in textual form so we have to convert them into numbers before they get fed to the model. Below we will replace the textual categories with numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e1cb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2501\n",
       "1    2500\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labeling with numerical values\n",
    "data['gender'] = data['gender'].replace(to_replace=['Female', 'Male'], value=[0, 1])\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43741a8",
   "metadata": {},
   "source": [
    "So we have now successfully converted the categories into numbers. Now let’s define input and output features. Out of 8 columns, The first 7 columns will be the input features and the last 8th column will be the output feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aa240fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input and output features\n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dc41b",
   "metadata": {},
   "source": [
    "Now we will create the training and testing patterns out of the above-defined features. Out of 5000 samples around, 4000 will be used for training and around 1000 samples will be used for testing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51503b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab78fe",
   "metadata": {},
   "source": [
    "Following we can also check the shapes above training and testing patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd36ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 7)\n",
      "(4000,)\n",
      "(1001, 7)\n",
      "(1001,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of train-test sets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f52dda",
   "metadata": {},
   "source": [
    "We have successfully created the training and testing patterns as we desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33b6d1",
   "metadata": {},
   "source": [
    "#### Defining a Neural Network Classifier\n",
    "\n",
    "To build neural networks are using the Keras library to facilitate all building blocks of the model. Now below will first import the Sequential model and Dense layer. This sequential model will hold the various layers of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeffd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for neural networks\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38bd57",
   "metadata": {},
   "source": [
    "Now will start the building model, first will initialize the sequential model then will input layer, hidden layer, and output layer. Both input and hidden layers will activate according to the Relu function and as we are dealing with a binary classification problem the neurons of output layers will be activated accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ba6115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                96        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209\n",
      "Trainable params: 209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=7, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Summary of the neural network model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc589f13",
   "metadata": {},
   "source": [
    "From the above model summary, we can see that the model has correctly initialized with all layers and neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d771f0",
   "metadata": {},
   "source": [
    "#### Training with different Optimizers\n",
    "\n",
    "Here while training with different optimizers we have initialized the same model for each optimizer, hence to avoid redundancy here we have shown how to initialize the model. The loss function that we are optimizing here is binary_crossentropy. \n",
    "\n",
    "So let’s start with the first optimizer which is stochastic gradient descent(SGD).\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "Below we will first import the SGD function from the keras.optimizer class, there will set learning as 0.01 and in the compile method, we will call this optimizer with loss function and accuracy metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c666b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Stochastic Gradient Descent as optimizer\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Compiling the classifier\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4b573",
   "metadata": {},
   "source": [
    "Now next we will train the network with a training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4817991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 3s 3ms/step - loss: 0.5051 - accuracy: 0.7610\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9340\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9408\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9467\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.9560\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1174 - accuracy: 0.9523\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9560\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1113 - accuracy: 0.9525\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1124 - accuracy: 0.9498\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1063 - accuracy: 0.9563\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1078 - accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.9565\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.9550\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1056 - accuracy: 0.9545\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9532\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1041 - accuracy: 0.9532\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9553\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9567\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2062e244e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36511e01",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a847690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 3ms/step - loss: 0.1063 - accuracy: 0.9560\n",
      "Training Accuracy: 95.60%\n",
      "\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9481\n",
      "Testing Accuracy: 94.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking training and test accuracies\n",
    "sgd_acc = model.evaluate(X_train, y_train)\n",
    "print (\"Training Accuracy: %.2f%%\\n\" % (sgd_acc[1]*100))\n",
    "sgd_loss = model.evaluate(X_test, y_test)\n",
    "print (\"Testing Accuracy: %.2f%%\\n\" % (sgd_loss[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b98ef7",
   "metadata": {},
   "source": [
    "As we can see from the above SGD has helped the model get accuracy above 95% on both train and test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e7286",
   "metadata": {},
   "source": [
    "### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "In a similar way that we have done for SGD, Adam optimizer will be used. Below we will compile, train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44654bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Adam as optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f04cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 2s 3ms/step - loss: 0.1053 - accuracy: 0.9555\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9575\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9615\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9567\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9597\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9572\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9603\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9535\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9595\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.9592\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9588\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9592\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9595\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9615\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9613\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9620\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.9613\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20634e0edf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the classifier\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "# Training the classifier\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb54546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9660\n",
      "Training Accuracy: 96.60%\n",
      "\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9600\n",
      "Testing Accuracy: 96.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking training and test accuracies\n",
    "adam_acc = model.evaluate(X_train, y_train)\n",
    "print (\"Training Accuracy: %.2f%%\\n\" % (adam_acc[1]*100))\n",
    "adam_loss = model.evaluate(X_test, y_test)\n",
    "print (\"Testing Accuracy: %.2f%%\\n\" % (adam_loss[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c008707",
   "metadata": {},
   "source": [
    "Using Adam optimizer we have got 96% accuracy on the training dataset and 96% on the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4a5f9",
   "metadata": {},
   "source": [
    "#### AdaGrad (Adaptive Gradient)\n",
    "\n",
    "Next will compile, train and evaluate the model using the AdaGrad optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "958670ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining AdaGrad as optimizer\n",
    "opt = keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "\n",
    "# Compiling the classifier\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dada0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 2s 3ms/step - loss: 0.0756 - accuracy: 0.9675\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9685\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9680\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9678\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9688\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9682\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9682\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9688\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9697\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9685\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9688\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9680\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9685\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9685\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9688\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9697\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9688\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9685\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9680\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20634e17220>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdff4255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9688\n",
      "Training Accuracy: 96.88%\n",
      "\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9580\n",
      "Testing Accuracy: 95.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking training and test accuracies\n",
    "agd_acc = model.evaluate(X_train, y_train)\n",
    "print (\"Training Accuracy: %.2f%%\\n\" % (agd_acc[1]*100))\n",
    "agd_loss = model.evaluate(X_test, y_test)\n",
    "print (\"Testing Accuracy: %.2f%%\\n\" % (agd_loss[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013195f",
   "metadata": {},
   "source": [
    "Using AdaGrad optimizer we have got training accuracy of 96.88% and test accuracy of 95.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51042a8d",
   "metadata": {},
   "source": [
    "#### RMSProp (Root Mean Squared Propagation)\n",
    "\n",
    "Finally, we will compile, train and evaluate the model using the RMSProp optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48aff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RMSProp as optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38a92726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RMSProp as optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83f7c869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9688\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9690\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9693\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9693\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9693\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9693\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9682\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9690\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9697\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9693\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9693\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9688\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9695\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9695\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9682\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9690\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9695\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2064f3fa0d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b65f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9693\n",
      "Training Accuracy: 96.93%\n",
      "\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9580\n",
      "Testing Accuracy: 95.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking training and test accuracies\n",
    "rms_acc = model.evaluate(X_train, y_train)\n",
    "print (\"Training Accuracy: %.2f%%\\n\" % (rms_acc[1]*100))\n",
    "rms_loss = model.evaluate(X_test, y_test)\n",
    "print (\"Testing Accuracy: %.2f%%\\n\" % (rms_loss[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ee367",
   "metadata": {},
   "source": [
    "So using the RMSProp optimizer we have got training accuracy of 96.93% and test accuracy of 95.8%.\n",
    "\n",
    "Now we have finally checked the accuracy for all the optimizers let’s summarize those all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016a3f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizers</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.95600</td>\n",
       "      <td>0.134855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.96600</td>\n",
       "      <td>0.107713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaGrad</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>0.96925</td>\n",
       "      <td>0.105703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Optimizers  Accuracy      Loss\n",
       "0        SGD   0.95600  0.134855\n",
       "1       Adam   0.96600  0.107713\n",
       "2    AdaGrad   0.96875  0.105492\n",
       "3    RMSProp   0.96925  0.105703"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarizing all\n",
    "opt_summary = pd.DataFrame(data={'Optimizers' : ['SGD', 'Adam', 'AdaGrad', 'RMSProp'],\n",
    "                   'Accuracy' : [sgd_acc[1], adam_acc[1], agd_acc[1], rms_acc[1]],\n",
    "                   'Loss' : [sgd_loss[0], adam_loss[0], agd_loss[0], rms_loss[0]],\n",
    "                  })\n",
    "opt_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3308439",
   "metadata": {},
   "source": [
    "As we can see above all four optimizers have performed for this binary classification problem.\n",
    "\n",
    "So this is how we can realize the optimizers for the neural network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
